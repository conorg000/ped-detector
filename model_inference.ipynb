{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFWT7J1Gs9Ly",
        "colab_type": "text"
      },
      "source": [
        "# Load Fine-tuned Model for Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjIYyxXwtJNt",
        "colab_type": "text"
      },
      "source": [
        "## Set up and requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MSkmXg0ursJ",
        "colab_type": "text"
      },
      "source": [
        "Clone Conor's ped-detector repo and install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT8unblNuOoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "c9e78d7d-9fb5-4e69-a14d-cf19e0e02bda"
      },
      "source": [
        "!git clone https://github.com/conorg000/ped-detector.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ped-detector'...\n",
            "remote: Enumerating objects: 2360, done.\u001b[K\n",
            "remote: Counting objects: 100% (2360/2360), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1887/1887), done.\u001b[K\n",
            "remote: Total 2437 (delta 495), reused 2333 (delta 472), pack-reused 77\u001b[K\n",
            "Receiving objects: 100% (2437/2437), 81.76 MiB | 28.50 MiB/s, done.\n",
            "Resolving deltas: 100% (528/528), done.\n",
            "Checking out files: 100% (2290/2290), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrFKGxkyt-CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "8cd3ec58-1627-4682-8eaf-13db78d3cee1"
      },
      "source": [
        "!pip install -r ped-detector/requirements.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 2)) (6.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 3)) (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r ped-detector/requirements.txt (line 7)) (1.17.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tarfile (from -r ped-detector/requirements.txt (line 8)) (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tarfile (from -r ped-detector/requirements.txt (line 8))\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZxeP7qEu8Ll",
        "colab_type": "text"
      },
      "source": [
        "Clone the Object Detection API and complete setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twd12BpzuEqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "7fb07ae5-76e3-44e0-fae4-4834b0163f90"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 34005 (delta 3), reused 2 (delta 0), pack-reused 33983\u001b[K\n",
            "Receiving objects: 100% (34005/34005), 512.24 MiB | 35.15 MiB/s, done.\n",
            "Resolving deltas: 100% (21795/21795), done.\n",
            "Checking out files: 100% (3012/3012), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn9JhKI2uI7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dXaap-AuKPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "e17b4632-5dcd-48e5-914b-22ea0968b818"
      },
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (6.2.2)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.14)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->Matplotlib>=2.1->object-detection==0.1) (45.1.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1017522 sha256=6a9d90283be75ec2143f2faef937d56d9096a7f0a81fd0ab899beb036a0383ce\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_gkpsb6/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jK6YWq1uXf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cp -r /content/models/research/slim/ /usr/local/lib/python3.6/dist-packages/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNwsPCPXuZMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd /usr/local/lib/python3.6/dist-packages/object_detection/slim\n",
        "python setup.py build\n",
        "python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejzgOmIxvTiJ",
        "colab_type": "text"
      },
      "source": [
        "## Inference function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jU2hTaXud3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "91de4069-7f3c-4173-a95e-f8b690ed5fa7"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile\n",
        "\"\"\"\n",
        "Script to load a TF inference graph and perform evaluation on an image file\n",
        "Returns bounding box coordinates, confidence, inference time\n",
        "\"\"\"\n",
        "\n",
        "# VARIABLES TO CHANGE\n",
        "# Change to local env path (wherever you cloned ped-detector)\n",
        "PATH = '/content/'\n",
        "# Change to desired jpeg image\n",
        "image_path = PATH + 'ped-detector/MOT16-01_000001.jpg'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual fine-tuned model that is used for the object detection.\n",
        "PATH_TO_CKPT = PATH + 'ped-detector/fine-tuned-model/frozen_inference_graph.pb'\n",
        "# For pre-trained model\n",
        "#PATH_TO_CKPT = PATH + 'ped-detector/pre-trained-model/frozen_inference_graph.pb'\n",
        "# Path to label map\n",
        "PATH_TO_LABELS = PATH + 'ped-detector/annotations/ped_label_map.pbtxt'\n",
        "# Detect just one class\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "def infer_img(image_path, confidence=0.3):\n",
        "  \"\"\"\n",
        "  Performs pedestrian object detection on an image\n",
        "  Returns bounding box coordinates (where confidence is over confidence%)\n",
        "  \n",
        "  Input:\n",
        "  image_path (string): path to .jpg file (change paths at top of this script as necessary)\n",
        "  confidence (float): confidence level (function only returns detections above this level)\n",
        "\n",
        "  Output:\n",
        "  results (list of tuples): list containing tuples of detections\n",
        "                            each tuple is of format (confidence, [ymin, xmin, ymax, xmax])\n",
        "                            bounding box coordinates are absolute (not relative)\n",
        "  time (float): inference time in seconds\n",
        "  \"\"\"\n",
        "  # Load the inference graph\n",
        "  detection_graph = tf.Graph()\n",
        "  with detection_graph.as_default():\n",
        "      od_graph_def = tf.GraphDef()\n",
        "      with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "          serialized_graph = fid.read()\n",
        "          od_graph_def.ParseFromString(serialized_graph)\n",
        "          tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "  # Match labels with names and their index\n",
        "  label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "  category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "  # Resize input image and direct to new path\n",
        "  img = Image.open(image_path)\n",
        "  img.thumbnail((600, 600))\n",
        "  image_path = image_path[:-4] + \"_resized.jpg\"\n",
        "  img.save(image_path)\n",
        "\n",
        "  # Start tf detection graph\n",
        "  with detection_graph.as_default():\n",
        "      with tf.Session(graph=detection_graph) as sess:\n",
        "          # Load tensors\n",
        "          image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "          detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "          detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "          detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "          num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "          # Load image\n",
        "          image = Image.open(image_path)\n",
        "          # Make into array\n",
        "          (im_width, im_height) = image.size\n",
        "          image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "          # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "          image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "          # Start inference timer\n",
        "          t0 = time.time()\n",
        "          # Get results from inference\n",
        "          (boxes, scores, classes, num) = sess.run(\n",
        "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "              feed_dict={image_tensor: image_np_expanded})\n",
        "          # Stop inference timer\n",
        "          t1 = time.time()\n",
        "\n",
        "  scores = scores.tolist()\n",
        "  scores = [float(x) for x in scores[0]]\n",
        "  scores = list(filter(lambda x: x > 0.3, scores))\n",
        "  num = len(scores)\n",
        "  inf_time = float(t1-t0)\n",
        "  bbs = boxes.tolist()[0][:num]\n",
        "  results = list(zip(scores, bbs))\n",
        "  for result in results:\n",
        "    # [ymin, xmin, ymax, xmax]\n",
        "    result[1][0] *= im_height\n",
        "    result[1][1] *= im_width\n",
        "    result[1][2] *= im_height\n",
        "    result[1][3] *= im_width\n",
        "  return (results, inf_time)\n",
        "\n",
        "coordinates, inf_time = infer_img(image_path)\n",
        "print(coordinates)\n",
        "print(inf_time)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.9990477561950684, [147.62185633182526, 233.07909965515137, 188.69647920131683, 248.1269359588623]), (0.8932743072509766, [131.4643134176731, 74.06489253044128, 179.7910720705986, 90.08933901786804]), (0.869631290435791, [140.24980255961418, 294.67660188674927, 193.00420653820038, 313.2203221321106]), (0.5049670338630676, [144.36111146211624, 390.92488288879395, 201.4330752491951, 412.1967315673828]), (0.36834245920181274, [131.8284563422203, 508.23705196380615, 184.72096687555313, 529.758095741272]), (0.3588935136795044, [140.45501899719238, 362.12918758392334, 192.76905077695847, 380.97782135009766]), (0.3502677083015442, [138.18467217683792, 311.02402210235596, 201.44870275259018, 333.73517990112305]), (0.3199266195297241, [139.15322586894035, 489.5513892173767, 187.0626618862152, 507.70164728164673])]\n",
            "0.7000503540039062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ2WU_ilvuN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}